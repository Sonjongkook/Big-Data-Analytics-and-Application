{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ICP10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaq5FNmmu8Y_"
      },
      "source": [
        "#Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yc0kKpb9UTK",
        "outputId": "a45e1175-ceaa-4d36-a4b9-2e7df05f8ec4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "#\n",
        "# Environment\n",
        "#\n",
        "env = gym.make('CartPole-v1')\n",
        "state = env.reset()\n",
        "action = env.action_space.sample()\n",
        "\n",
        "print('State space: ', env.observation_space)\n",
        "print('Initial state: ', state)\n",
        "print('\\nAction space: ', env.action_space)\n",
        "print('Random action: ', action)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "State space:  Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32)\n",
            "Initial state:  [ 0.02685345  0.0105703  -0.02593711  0.00075185]\n",
            "\n",
            "Action space:  Discrete(2)\n",
            "Random action:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBb5BKr5CIW-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RQ01Lh5vAWM"
      },
      "source": [
        "#DQN modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iT8AiI9CJDK"
      },
      "source": [
        "# DQN Modeling\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "num_state = env.observation_space.shape[0]\n",
        "num_action = env.action_space.n\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "# Hidden layer with 512 nodes\n",
        "model.add(Dense(512, input_dim= num_state, kernel_initializer='he_uniform', activation='relu'))\n",
        "# Hidden layer with 256 nodes\n",
        "model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
        "# Hidden layer with 64 nodes\n",
        "model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(num_action, activation='linear'))\n",
        "model.compile(loss='mse', optimizer=\"adam\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7eq0VRNCIEj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSveeSm3Fn55"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFNDdG79gmg1"
      },
      "source": [
        "#Learning process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px3nl36z9UTS",
        "outputId": "d8d1cfe4-d1d7-4e4e-dbc9-6507a76ab999",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import random\n",
        "from collections import deque\n",
        "from tqdm import tqdm\n",
        "\n",
        "num_episode = 300\n",
        "memory = deque(maxlen=2000)\n",
        "\n",
        "# Hyper parameter\n",
        "epsilon = 0.3\n",
        "gamma = 0.95\n",
        "batch_size = 32\n",
        "\n",
        "# DQN Learning\n",
        "for episode in tqdm(range(num_episode)):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    while not done:\n",
        "        if np.random.uniform() < epsilon:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            q_value = model.predict(state.reshape(1, num_state))\n",
        "            action = np.argmax(q_value[0])\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "        # Memory\n",
        "        memory.append((state, action, reward, next_state, done))\n",
        "        \n",
        "        state = next_state\n",
        "    \n",
        "    # Replay\n",
        "    if len(memory) > batch_size:\n",
        "        mini_batch = random.sample(memory, batch_size)\n",
        "        for state, action, reward, next_state, done in mini_batch:\n",
        "            if done:\n",
        "                target = reward\n",
        "            else:\n",
        "                target = reward + gamma * (np.max(model.predict(next_state.reshape(1, num_state))[0]))\n",
        "            q_value = model.predict(state.reshape(1, num_state))\n",
        "            q_value[0][action] = target\n",
        "            model.fit(state.reshape(1, num_state), q_value, epochs=1, verbose=0)\n",
        "\n",
        "env.close()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 300/300 [17:26<00:00,  3.49s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFe7gEAAFp5K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MumTFJ5gFqKr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxpRhHHEguqW"
      },
      "source": [
        "#Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKwSoUzg9UTW"
      },
      "source": [
        "import os\n",
        "\n",
        "save_dir = os.getcwd()\n",
        "model_name = 'keras_dqn_trained_model.h5'\n",
        "\n",
        "# Save model and weights\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_lf_McJHgvQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlVN9yQ6iQdz"
      },
      "source": [
        "##Install for visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoVf_FR1HhEq",
        "outputId": "731468db-6628-4dd9-8ed2-07c3774d3628",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install gym pyvirtualdisplay"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.17.3)\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/8a/643043cc70791367bee2d19eb20e00ed1a246ac48e5dbe57bbbcc8be40a9/PyVirtualDisplay-1.3.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.18.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.5.0)\n",
            "Collecting EasyProcess\n",
            "  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
            "Successfully installed EasyProcess-0.3 pyvirtualdisplay-1.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0gMAY8ZHlRA",
        "outputId": "2d846c09-9e4b-4059-f475-9d56acc3df64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!apt-get install xvfb python-opengl ffmpeg"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "Suggested packages:\n",
            "  libgle3\n",
            "The following NEW packages will be installed:\n",
            "  python-opengl xvfb\n",
            "0 upgraded, 2 newly installed, 0 to remove and 11 not upgraded.\n",
            "Need to get 1,280 kB of archives.\n",
            "After this operation, 7,682 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.7 [783 kB]\n",
            "Fetched 1,280 kB in 0s (12.1 MB/s)\n",
            "Selecting previously unselected package python-opengl.\n",
            "(Reading database ... 144628 files and directories currently installed.)\n",
            "Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.7_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.7) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-1) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.7) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCPUQsl3HliL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePVOPZuZHo7x"
      },
      "source": [
        "from gym.wrappers import Monitor\n",
        "\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "def show_video(file_infix):\n",
        "    with open('./video/openaigym.video.%s.video000000.mp4' % file_infix, 'r+b') as f:\n",
        "        video = f.read()\n",
        "        encoded = base64.b64encode(video)\n",
        "        ipythondisplay.display(HTML(data='''<video alt=\"Trained CartPole\" autoplay \n",
        "                loop style=\"height: 200px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "                 </video>'''.format(encoded.decode('ascii'))))\n",
        "    \n",
        "def wrap_env(env):\n",
        "    env = Monitor(env, './video', force=True)\n",
        "    return env"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxcgkEjUiZD7"
      },
      "source": [
        "## load the model that we saved"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KsFN0VLHqrX"
      },
      "source": [
        "from  tensorflow.keras.models import load_model\n",
        "import os\n",
        "\n",
        "load_dir = os.getcwd()\n",
        "model_name = 'keras_dqn_trained_model.h5'\n",
        "model_path = os.path.join(load_dir, model_name)\n",
        "model = load_model(model_path)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C1PFB3JHtV7",
        "outputId": "8d8a0bec-9887-4c3b-c7e3-ac68e88607b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "num_state = env.observation_space.shape[0]\n",
        "env = wrap_env(gym.make('CartPole-v1'))\n",
        "state = env.reset()\n",
        "done = False\n",
        "\n",
        "mem = []\n",
        "\n",
        "while not done:\n",
        "    state = np.array(state).reshape(1, num_state)\n",
        "    q_value = model.predict(state)\n",
        "    mem.append(q_value[0])\n",
        "    action = np.argmax(q_value[0])\n",
        "    state, reward, done, info = env.step(action)\n",
        "\n",
        "file_infix = env.file_infix\n",
        "env.close()\n",
        "\n",
        "show_video(file_infix)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video alt=\"Trained CartPole\" autoplay \n",
              "                loop style=\"height: 200px;\">\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "                 </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPHGBfzLIp9I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17HtI3sIIqLm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}